{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_project1(emoji).ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "# import keras\n",
        "from keras.layers.wrappers import Bidirectional\n",
        "from keras.layers import Embedding\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn import preprocessing\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, SimpleRNN, Dense, Dropout\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "tmmz3XO_vwY7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_tte = Sequential()\n",
        "model_tte.add(LSTM(units=64, input_shape=(168, 50), return_sequences=True))\n",
        "model_tte.add(Dropout(0.3))\n",
        "model_tte.add(LSTM(units=32))\n",
        "model_tte.add(Dropout(0.2))\n",
        "model_tte.add(Dense(units=10, activation='relu'))\n",
        "model_tte.add(Dense(units=6, activation='softmax'))\n",
        "\n",
        "model_tte.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['acc'])"
      ],
      "metadata": {
        "id": "QJzZLcIA534V"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def intialize_emb_matrix(file):\n",
        "    embedding_matrix = {}\n",
        "    for line in file:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        embedding = np.array(values[1:], dtype='float64')\n",
        "        embedding_matrix[word] = embedding\n",
        "\n",
        "    return embedding_matrix \n",
        "\n",
        "def get_emb_data(data, max_len, file):\n",
        "#     max_len = 168\n",
        "    embedding_matrix = intialize_emb_matrix(file)\n",
        "    embedding_data = np.zeros((len(data), max_len, 50))  # from glove6B50d\n",
        "    \n",
        "    for idx in range(data.shape[0]):\n",
        "        words_in_sentence = data[idx].split()\n",
        "        \n",
        "        for i in range(len(words_in_sentence)):\n",
        "            if embedding_matrix.get(words_in_sentence[i].lower()) is not None:\n",
        "                embedding_data[idx][i] = embedding_matrix[words_in_sentence[i].lower()]\n",
        "                \n",
        "    return embedding_data"
      ],
      "metadata": {
        "id": "69qvsTg83uuM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('drive/MyDrive/emoji/glove.6B.50d.txt',encoding='utf8')\n",
        "data = pd.read_csv('drive/MyDrive/emoji/new_dataset.csv',sep=',')\n",
        "X_train, y_train = data['Tweet'].values, data['Emoji'].values\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "\n",
        "print(X_train.shape,y_train.shape)\n",
        "\n",
        "\n",
        "X_temb = get_emb_data(X_train, 168, file)\n",
        "y_train = to_categorical(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrOjhOmD0JSf",
        "outputId": "d5d11acc-7520-4e2c-a0c1-0629164e6a59"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19174,) (19174,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_temb.shape,y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHQNkmB76Yak",
        "outputId": "d688ec29-4174-4008-b87d-229eba9151aa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19174, 168, 50) (19174, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "res = model_tte.fit(X_temb, y_train, validation_split=0.2, batch_size=128, epochs=20, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si-HUz_r6N2J",
        "outputId": "36b29257-a632-4127-e85f-846dacbe3fb1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "120/120 - 44s - loss: 1.6621 - acc: 0.3552 - val_loss: 1.6058 - val_acc: 0.3909 - 44s/epoch - 363ms/step\n",
            "Epoch 2/20\n",
            "120/120 - 39s - loss: 1.6297 - acc: 0.3673 - val_loss: 1.6035 - val_acc: 0.3909 - 39s/epoch - 324ms/step\n",
            "Epoch 3/20\n",
            "120/120 - 39s - loss: 1.6266 - acc: 0.3685 - val_loss: 1.6043 - val_acc: 0.3909 - 39s/epoch - 322ms/step\n",
            "Epoch 4/20\n",
            "120/120 - 38s - loss: 1.6270 - acc: 0.3703 - val_loss: 1.6039 - val_acc: 0.3909 - 38s/epoch - 317ms/step\n",
            "Epoch 5/20\n",
            "120/120 - 38s - loss: 1.6249 - acc: 0.3703 - val_loss: 1.6037 - val_acc: 0.3909 - 38s/epoch - 315ms/step\n",
            "Epoch 6/20\n",
            "120/120 - 38s - loss: 1.6245 - acc: 0.3703 - val_loss: 1.6044 - val_acc: 0.3909 - 38s/epoch - 314ms/step\n",
            "Epoch 7/20\n",
            "120/120 - 38s - loss: 1.6247 - acc: 0.3702 - val_loss: 1.6049 - val_acc: 0.3909 - 38s/epoch - 314ms/step\n",
            "Epoch 8/20\n",
            "120/120 - 38s - loss: 1.6235 - acc: 0.3702 - val_loss: 1.6027 - val_acc: 0.3909 - 38s/epoch - 313ms/step\n",
            "Epoch 9/20\n",
            "120/120 - 38s - loss: 1.6248 - acc: 0.3701 - val_loss: 1.6042 - val_acc: 0.3909 - 38s/epoch - 314ms/step\n",
            "Epoch 10/20\n",
            "120/120 - 38s - loss: 1.6233 - acc: 0.3702 - val_loss: 1.6047 - val_acc: 0.3909 - 38s/epoch - 314ms/step\n",
            "Epoch 11/20\n",
            "120/120 - 38s - loss: 1.6239 - acc: 0.3702 - val_loss: 1.6026 - val_acc: 0.3909 - 38s/epoch - 315ms/step\n",
            "Epoch 12/20\n",
            "120/120 - 38s - loss: 1.6237 - acc: 0.3702 - val_loss: 1.6036 - val_acc: 0.3909 - 38s/epoch - 314ms/step\n",
            "Epoch 13/20\n",
            "120/120 - 38s - loss: 1.6230 - acc: 0.3702 - val_loss: 1.6050 - val_acc: 0.3909 - 38s/epoch - 314ms/step\n",
            "Epoch 14/20\n",
            "120/120 - 38s - loss: 1.6235 - acc: 0.3702 - val_loss: 1.6032 - val_acc: 0.3909 - 38s/epoch - 315ms/step\n",
            "Epoch 15/20\n",
            "120/120 - 38s - loss: 1.6235 - acc: 0.3702 - val_loss: 1.6043 - val_acc: 0.3909 - 38s/epoch - 313ms/step\n",
            "Epoch 16/20\n",
            "120/120 - 37s - loss: 1.6227 - acc: 0.3702 - val_loss: 1.6043 - val_acc: 0.3909 - 37s/epoch - 312ms/step\n",
            "Epoch 17/20\n",
            "120/120 - 38s - loss: 1.6229 - acc: 0.3702 - val_loss: 1.6050 - val_acc: 0.3909 - 38s/epoch - 313ms/step\n",
            "Epoch 18/20\n",
            "120/120 - 38s - loss: 1.6234 - acc: 0.3702 - val_loss: 1.6055 - val_acc: 0.3909 - 38s/epoch - 314ms/step\n",
            "Epoch 19/20\n",
            "120/120 - 38s - loss: 1.6226 - acc: 0.3702 - val_loss: 1.6029 - val_acc: 0.3909 - 38s/epoch - 315ms/step\n",
            "Epoch 20/20\n",
            "120/120 - 38s - loss: 1.6228 - acc: 0.3702 - val_loss: 1.6050 - val_acc: 0.3909 - 38s/epoch - 315ms/step\n"
          ]
        }
      ]
    }
  ]
}