{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_project1(emoji).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "# import keras\n",
        "from keras.layers.wrappers import Bidirectional\n",
        "from keras.layers import Embedding\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn import preprocessing\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, SimpleRNN, Dense, Dropout\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "tmmz3XO_vwY7"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_tte = Sequential()\n",
        "model_tte.add(LSTM(units=64, input_shape=(168, 50), return_sequences=True))\n",
        "model_tte.add(Dropout(0.3))\n",
        "model_tte.add(LSTM(units=32))\n",
        "model_tte.add(Dropout(0.2))\n",
        "model_tte.add(Dense(units=10, activation='relu'))\n",
        "model_tte.add(Dense(units=6, activation='softmax'))\n",
        "\n",
        "model_tte.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['acc'])"
      ],
      "metadata": {
        "id": "QJzZLcIA534V"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def intialize_emb_matrix(file):\n",
        "    embedding_matrix = {}\n",
        "    for line in file:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        embedding = np.array(values[1:], dtype='float64')\n",
        "        embedding_matrix[word] = embedding\n",
        "\n",
        "    return embedding_matrix \n",
        "\n",
        "def get_emb_data(data, max_len, file):\n",
        "#     max_len = 168\n",
        "    embedding_matrix = intialize_emb_matrix(file)\n",
        "    embedding_data = np.zeros((len(data), max_len, 50))  # from glove6B50d\n",
        "    \n",
        "    for idx in range(data.shape[0]):\n",
        "        words_in_sentence = data[idx].split()\n",
        "        \n",
        "        for i in range(len(words_in_sentence)):\n",
        "            if embedding_matrix.get(words_in_sentence[i].lower()) is not None:\n",
        "                embedding_data[idx][i] = embedding_matrix[words_in_sentence[i].lower()]\n",
        "                \n",
        "    return embedding_data"
      ],
      "metadata": {
        "id": "69qvsTg83uuM"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('drive/MyDrive/emoji/glove.6B.50d.txt',encoding='utf8')\n",
        "data = pd.read_csv('drive/MyDrive/emoji/twitter_dataset.csv',sep=',')\n",
        "X_train, y_train = data['tweet'].values, data['emoji'].values\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "\n",
        "print(X_train.shape,y_train.shape)\n",
        "\n",
        "\n",
        "X_temb = get_emb_data(X_train, 168, file)\n",
        "y_train = to_categorical(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrOjhOmD0JSf",
        "outputId": "722a0ec0-c7f6-4ac6-96d8-2e307da8faf6"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(793,) (793,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_temb.shape,y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHQNkmB76Yak",
        "outputId": "04762aa2-aa7d-4bb9-d871-0f1785ae8777"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(793, 100, 50) (793, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "res = model_tte.fit(X_temb, y_train, validation_split=0.2, batch_size=128, epochs=20, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si-HUz_r6N2J",
        "outputId": "88780385-e8df-45b9-b6a5-7bf8d0cba1fb"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "5/5 - 6s - loss: 1.7895 - acc: 0.2129 - val_loss: 1.8370 - val_acc: 0.0000e+00 - 6s/epoch - 1s/step\n",
            "Epoch 2/20\n",
            "5/5 - 1s - loss: 1.7811 - acc: 0.2192 - val_loss: 1.9195 - val_acc: 0.0000e+00 - 1s/epoch - 204ms/step\n",
            "Epoch 3/20\n",
            "5/5 - 1s - loss: 1.7675 - acc: 0.2240 - val_loss: 2.1639 - val_acc: 0.0000e+00 - 1s/epoch - 209ms/step\n",
            "Epoch 4/20\n",
            "5/5 - 1s - loss: 1.7392 - acc: 0.2208 - val_loss: 2.7362 - val_acc: 0.0000e+00 - 1s/epoch - 204ms/step\n",
            "Epoch 5/20\n",
            "5/5 - 1s - loss: 1.7344 - acc: 0.2303 - val_loss: 2.8644 - val_acc: 0.0000e+00 - 1s/epoch - 212ms/step\n",
            "Epoch 6/20\n",
            "5/5 - 1s - loss: 1.7387 - acc: 0.2224 - val_loss: 2.7464 - val_acc: 0.0000e+00 - 1s/epoch - 201ms/step\n",
            "Epoch 7/20\n",
            "5/5 - 1s - loss: 1.7299 - acc: 0.2271 - val_loss: 2.6846 - val_acc: 0.0000e+00 - 998ms/epoch - 200ms/step\n",
            "Epoch 8/20\n",
            "5/5 - 1s - loss: 1.7279 - acc: 0.2224 - val_loss: 2.8078 - val_acc: 0.0000e+00 - 1s/epoch - 203ms/step\n",
            "Epoch 9/20\n",
            "5/5 - 1s - loss: 1.7224 - acc: 0.2066 - val_loss: 3.0147 - val_acc: 0.0000e+00 - 1s/epoch - 200ms/step\n",
            "Epoch 10/20\n",
            "5/5 - 1s - loss: 1.7191 - acc: 0.2192 - val_loss: 2.8384 - val_acc: 0.0063 - 1s/epoch - 204ms/step\n",
            "Epoch 11/20\n",
            "5/5 - 1s - loss: 1.7222 - acc: 0.2019 - val_loss: 3.1320 - val_acc: 0.0000e+00 - 1s/epoch - 202ms/step\n",
            "Epoch 12/20\n",
            "5/5 - 1s - loss: 1.7196 - acc: 0.2145 - val_loss: 3.0107 - val_acc: 0.0000e+00 - 991ms/epoch - 198ms/step\n",
            "Epoch 13/20\n",
            "5/5 - 1s - loss: 1.7079 - acc: 0.2224 - val_loss: 2.9662 - val_acc: 0.0063 - 1s/epoch - 202ms/step\n",
            "Epoch 14/20\n",
            "5/5 - 1s - loss: 1.7142 - acc: 0.2098 - val_loss: 2.8423 - val_acc: 0.0063 - 998ms/epoch - 200ms/step\n",
            "Epoch 15/20\n",
            "5/5 - 1s - loss: 1.7109 - acc: 0.2192 - val_loss: 3.1749 - val_acc: 0.0000e+00 - 1s/epoch - 204ms/step\n",
            "Epoch 16/20\n",
            "5/5 - 1s - loss: 1.7064 - acc: 0.2145 - val_loss: 3.0359 - val_acc: 0.0000e+00 - 1s/epoch - 202ms/step\n",
            "Epoch 17/20\n",
            "5/5 - 1s - loss: 1.7070 - acc: 0.2240 - val_loss: 2.7785 - val_acc: 0.0000e+00 - 1s/epoch - 203ms/step\n",
            "Epoch 18/20\n",
            "5/5 - 1s - loss: 1.7100 - acc: 0.2461 - val_loss: 3.0450 - val_acc: 0.0000e+00 - 1s/epoch - 203ms/step\n",
            "Epoch 19/20\n",
            "5/5 - 1s - loss: 1.7029 - acc: 0.2303 - val_loss: 2.9019 - val_acc: 0.0000e+00 - 1s/epoch - 200ms/step\n",
            "Epoch 20/20\n",
            "5/5 - 1s - loss: 1.7006 - acc: 0.2350 - val_loss: 2.8078 - val_acc: 0.0000e+00 - 997ms/epoch - 199ms/step\n"
          ]
        }
      ]
    }
  ]
}